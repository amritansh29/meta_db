You are assisting with a medical imaging metadata project built to manage, extract, and query DICOM metadata for research purposes.

ğŸ§ª PROJECT GOAL
Build a modular FastAPI + MongoDB application that:

Allows researchers to define "jobs" to extract data from DICOM archives using accession numbers (external PACS query integration in scope for future).

Extracts DICOM metadata from a mounted folder archive (/usr/local/share/LIDC-IDRI-DICOM/).

Inserts structured metadata into a MongoDB database with hierarchical relationships.

Supports filtering and querying at the study and series levels.

Will expose a dashboard for data exploration, and in the future, support:

Raw MongoDB queries

User-friendly UI filters

Natural Language (NLP) queries

ğŸ“‚ DIRECTORY STRUCTURE
graphql
Copy
Edit
meta_db/
|-->LIDC-IDRI-DICOM #folder with dicom files
â”œâ”€â”€ db_api/               # FastAPI backend for insertion/querying MongoDB
â”‚   â”œâ”€â”€ db.py             # MongoDB connection
â”‚   â”œâ”€â”€ main.py           # FastAPI entrypoint
â”‚   â”œâ”€â”€ models.py         # Pydantic models (Researcher, Study, Series, Instance)
â”‚   â”œâ”€â”€ routes.py         # API routes for inserting and linking data
â”‚   â””â”€â”€ validators.py     # Validation logic (coming soon)
â”œâ”€â”€ meta_extractor/       # DICOM metadata extractor using pydicom
â”‚   â”œâ”€â”€ extractor.py      # Reads DICOMs and returns structured dicts
â”‚   â””â”€â”€ conf/             # Contains StudyFeatures.txt, SeriesFeatures.txt, InstanceFeatures.txt
â”œâ”€â”€ driver.py             # Calls extractor, validates metadata, sends to API
â”œâ”€â”€ Dockerfile            # Runs API + driver in container
â”œâ”€â”€ docker-compose.yml    # MongoDB, FastAPI, Mongo Express
â”œâ”€â”€ requirements.txt      # Python dependencies
ğŸ§¬ CURRENT MONGODB SCHEMA
researchers
Stores researcher metadata:

json
Copy
Edit
{
  "_id": ObjectId(),
  "researcher_id": "r12345",
  "name": "Dr. Alice Lee",
  "email": "alice@example.org",
  "jobs": [ObjectId("...")]
}
collections
Each represents a dataset or grouping:

json
Copy
Edit
{
  "_id": ObjectId(),
  "name": "LIDC-IDRI",
  "cases": [
    {
      "case_id": "CASE001",
      "patient_id": "PATIENT0001",
      "accession_numbers": ["ACC123"]
    }
  ]
}
studies
DICOM study-level metadata:

json
Copy
Edit
{
  "study_instance_uid": "1.2.3...",
  "accession_number": "ACC123",
  "patient_id": "PATIENT0001",
  "metadata": { "Modality": "CT", ... },
  "collection_ids": [ObjectId("...")],
  "series": [{ "series_id": ObjectId("..."), ... }]
}
series
Series-level metadata with link to parent study:

json
Copy
Edit
{
  "series_instance_uid": "...",
  "study_id": ObjectId("..."),
  "metadata": { "BodyPartExamined": "CHEST" },
  "instances": [ObjectId("...")]
}
instances
Per-DICOM-file metadata:

json
Copy
Edit
{
  "sop_instance_uid": "...",
  "series_id": ObjectId("..."),
  "metadata": { "InstanceNumber": 12, ... }
}
âš™ï¸ CURRENT FUNCTIONALITY
âœ… Implemented:

FastAPI endpoints for inserting:

/researchers

/collections

/studies

/series (with smart linking to studies)

/instances (coming next, will link to series)

Extractor reads and groups DICOM metadata by study, series, instance

driver.py handles orchestrating:

metadata extraction

validating researcher, collection, and hierarchy

calling FastAPI endpoints in correct order

ğŸ”„ In Progress:

Add post-hoc /link route to fix or validate cross-references.

Ensure robust validation when inserting (study_id exists, etc.).

Add indexing and promoted fields to documents.

ğŸ–¼ï¸ Future:

Dashboard: raw query â†’ filter UI â†’ NLP query search.

ğŸ“Œ REPO
GitHub: https://github.com/amritansh29/meta_db